{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from keras.models import Sequential, Model\r\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, Input, Concatenate, Conv1D,Flatten, Dropout, MaxPooling1D\r\n",
    "from keras.callbacks import TensorBoard\r\n",
    "from keras.optimizers import Adam\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import datetime\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from keras.callbacks import TensorBoard\r\n",
    "import tensorflow as tf\r\n",
    "import math\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.layers import Dropout\r\n",
    "from keras.layers import *\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from geneticalgorithm import geneticalgorithm as ga"
   ],
   "outputs": [],
   "metadata": {
    "id": "IrfBUMANpANo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "call_df = pd.read_csv('')\r\n",
    "History = pd.read_csv('')\r\n",
    "risk_free_asset = pd.read_csv('')"
   ],
   "outputs": [],
   "metadata": {
    "id": "VdLGUr9cpAA3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Format and split data before training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# Add risk-free asset as feature to df on date\r\n",
    "n_timesteps = 1\r\n",
    "\r\n",
    "padded = np.insert(risk_free_asset.Rate.values, 0, np.array([np.nan] * n_timesteps))\r\n",
    "rolled = np.column_stack([np.roll(padded, i) for i in range(n_timesteps)])\r\n",
    "rolled = rolled[~np.isnan(rolled).any(axis=1)]\r\n",
    "rolled = np.column_stack((risk_free_asset.Date.values[n_timesteps - 1:], rolled))\r\n",
    "price_history = pd.DataFrame(data=rolled)\r\n",
    "joined = call_df.join(price_history.set_index(0), on='Date')\r\n",
    "\r\n",
    "joined['r'] = joined[1]\r\n",
    "call_df = joined.drop(columns=[1,'LTP', 'Risk_free_rate'],axis=1)\r\n",
    "\r\n",
    "\r\n",
    "#Creates the stock dynamics for the n_timesteps back.\r\n",
    "\r\n",
    "underlying=History\r\n",
    "n_timesteps = 30\r\n",
    "padded = np.insert(underlying.Close.values, 0, np.array([np.nan] * n_timesteps))\r\n",
    "rolled = np.column_stack([np.roll(padded, i) for i in range(n_timesteps)])\r\n",
    "rolled = rolled[~np.isnan(rolled).any(axis=1)]\r\n",
    "rolled = np.column_stack((underlying.Date.values[n_timesteps - 1:], rolled))\r\n",
    "price_history = pd.DataFrame(data=rolled)\r\n",
    "joined = call_df.join(price_history.set_index(0), on='Date')\r\n",
    "call_df=joined\r\n",
    "call_df = call_df.drop(columns=['Date','Expiry'])\r\n",
    "call_df = call_df.dropna()\r\n",
    "\r\n",
    "features = 4"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "A-xnbEDLqXau",
    "outputId": "bb2ad4a7-211c-41ec-9c93-66ba084fadf2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "call_df=call_df[['Strike Price','Close','nDiff','r','Underlying Value']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "call_X_train, call_X_test, call_y_train, call_y_test = train_test_split(call_df.drop(columns=['Close'],axis=1).values,\r\n",
    "                                                                        (call_df['Close']).values,\r\n",
    "                                                                        #shuffle=False,\r\n",
    "                                                                         random_state=42,\r\n",
    "                                                                  test_size=0.01)\r\n",
    "call_X_test= np.array(call_X_test, dtype=np.float64)\r\n",
    "call_y_test= np.array(call_y_test, dtype=np.float64)\r\n",
    "call_X_train=np.asarray(call_X_train).astype(np.float64)\r\n",
    "\r\n",
    "\r\n",
    "call_X_train = [call_X_train[:, -n_timesteps:].reshape(call_X_train.shape[0], n_timesteps, 1), call_X_train[:, :4]]\r\n",
    "call_X_test = [call_X_test[:, -n_timesteps:].reshape(call_X_test.shape[0], n_timesteps, 1), call_X_test[:, :4]]\r\n",
    "\r\n",
    "\r\n",
    "call_y_train=np.asarray(call_y_train).astype(np.float64)"
   ],
   "outputs": [],
   "metadata": {
    "id": "TYXn2YQMtVcu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calibrate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "def CNN():\r\n",
    "    def f(x):\r\n",
    "       first_neuron,second_neuron,third_neuron,dropout,hidden_layers,pool=x\r\n",
    "       with tf.device('/Gpu:0'): \r\n",
    "        close_history = Input((n_timesteps, 1))\r\n",
    "        input2 = Input((features,))\r\n",
    "\r\n",
    "        model = Sequential()\r\n",
    "        model.add(Conv1D(first_neuron, kernel_size=1, activation='relu', input_shape=(n_timesteps,1)))\r\n",
    "        model.add(MaxPooling1D(pool_size=int(pool)))\r\n",
    "        model.add(Flatten())\r\n",
    "        model.add(Dense(second_neuron, activation='relu'))\r\n",
    "        model.add(Dropout(dropout/10))\r\n",
    "        model.add(Dense(third_neuron, activation='softmax'))\r\n",
    "\r\n",
    "        ## final layer\r\n",
    "        input1 = model(close_history)\r\n",
    "\r\n",
    "        connect = Concatenate()([input1, input2])\r\n",
    "\r\n",
    "        for _ in range(int(hidden_layers) - 1):\r\n",
    "          connect = Dense(100)(connect)\r\n",
    "          connect = BatchNormalization()(connect)\r\n",
    "          connect = LeakyReLU()(connect)\r\n",
    "\r\n",
    "        predict = Dense(1, activation='relu')(connect)\r\n",
    "        model=Model(inputs=[close_history, input2], outputs=predict)\r\n",
    "\r\n",
    "\r\n",
    "        #model.compile(optimizer=Adam(learning_rate=params['lr']), loss='mse')\r\n",
    "        model.compile(optimizer=Adam(learning_rate=1e-3), loss='mse')\r\n",
    "\r\n",
    "        out = model.fit(call_X_train, call_y_train, \r\n",
    "                    batch_size=250,\r\n",
    "                    epochs=300,\r\n",
    "                    validation_split = 0.01,\r\n",
    "                    validation_data=(call_X_test, call_y_test),\r\n",
    "                    callbacks=[TensorBoard()],\r\n",
    "                    verbose=0)\r\n",
    "        \r\n",
    "       return np.sqrt(np.mean(np.square(call_y_test-model.predict(call_X_test, batch_size=250).reshape(call_y_test.shape[0]))))\r\n",
    "        \r\n",
    "    \r\n",
    "    varbound=np.array([[1,200],[1,200],[1,200],[0,2],[1,12],[2,8]])\r\n",
    "    algorithm_param = {'max_num_iteration': 100,\\\r\n",
    "                   'population_size':12,\\\r\n",
    "                   'mutation_probability':0.1,\\\r\n",
    "                   'elit_ratio': 0.01,\\\r\n",
    "                   'crossover_probability': 0.5,\\\r\n",
    "                   'parents_portion': 0.3,\\\r\n",
    "                   'crossover_type':'uniform',\\\r\n",
    "                   'max_iteration_without_improv':5}\r\n",
    "    model=ga(function=f,\\\r\n",
    "            dimension=6,\\\r\n",
    "            variable_type='int',\\\r\n",
    "            variable_boundaries=varbound,\\\r\n",
    "            function_timeout=3000,\r\n",
    "            algorithm_parameters=algorithm_param,\r\n",
    "         convergence_curve=True,\r\n",
    "         progress_bar=True)\r\n",
    "\r\n",
    "    model.run()\r\n",
    "    return model.best_variable"
   ],
   "outputs": [],
   "metadata": {
    "id": "P14CcOni2Ejx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Params=CNN()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "U04Fubhl2V0G",
    "outputId": "4bdea5a1-f93e-4cb8-8c9c-280638bcc962"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Option traning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "first_neuron, second_neuron, third_neuron, dropout, hidden_layers, pool= Params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read all data again to disregard all changes made previously\r\n",
    "\r\n",
    "call_df = pd.read_csv('')\r\n",
    "History = pd.read_csv('')\r\n",
    "risk_free_asset = pd.read_csv('')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# Add risk-free asset as feature to df on date\r\n",
    "n_timesteps = 1\r\n",
    "\r\n",
    "padded = np.insert(risk_free_asset.Rate.values, 0, np.array([np.nan] * n_timesteps))\r\n",
    "rolled = np.column_stack([np.roll(padded, i) for i in range(n_timesteps)])\r\n",
    "rolled = rolled[~np.isnan(rolled).any(axis=1)]\r\n",
    "rolled = np.column_stack((risk_free_asset.Date.values[n_timesteps - 1:], rolled))\r\n",
    "price_history = pd.DataFrame(data=rolled)\r\n",
    "joined = call_df.join(price_history.set_index(0), on='Date')\r\n",
    "\r\n",
    "joined['r'] = joined[1]\r\n",
    "call_df = joined.drop(columns=[1,'LTP', 'Risk_free_rate'],axis=1)\r\n",
    "\r\n",
    "\r\n",
    "#Creates the stock dynamics for the n_timesteps back.\r\n",
    "\r\n",
    "underlying=History\r\n",
    "n_timesteps = 30\r\n",
    "padded = np.insert(underlying.Close.values, 0, np.array([np.nan] * n_timesteps))\r\n",
    "rolled = np.column_stack([np.roll(padded, i) for i in range(n_timesteps)])\r\n",
    "rolled = rolled[~np.isnan(rolled).any(axis=1)]\r\n",
    "rolled = np.column_stack((underlying.Date.values[n_timesteps - 1:], rolled))\r\n",
    "price_history = pd.DataFrame(data=rolled)\r\n",
    "joined = call_df.join(price_history.set_index(0), on='Date')\r\n",
    "call_df=joined\r\n",
    "call_df = call_df.drop(columns=['Date','Expiry'])\r\n",
    "call_df = call_df.dropna()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "call_X_train, call_X_test, call_y_train, call_y_test = train_test_split(call_df.drop(columns=['Close'],axis=1).values,\r\n",
    "                                                                        (call_df['Close']).values,\r\n",
    "                                                                        #shuffle=False,\r\n",
    "                                                                         random_state=42,\r\n",
    "                                                                  test_size=0.01)\r\n",
    "call_X_test= np.array(call_X_test, dtype=np.float64)\r\n",
    "call_y_test= np.array(call_y_test, dtype=np.float64)\r\n",
    "call_X_train=np.asarray(call_X_train).astype(np.float64)\r\n",
    "\r\n",
    "call_y_train=np.asarray(call_y_train).astype(np.float64)\r\n",
    "\r\n",
    "n_timesteps = 30\r\n",
    "features = 4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "close_history = Input((n_timesteps, 1))\r\n",
    "input2 = Input((features,))\r\n",
    "\r\n",
    "model = Sequential()\r\n",
    "model.add(Conv1D(first_neuron, kernel_size=1, activation='relu', input_shape=(n_timesteps,1)))\r\n",
    "model.add(MaxPooling1D(pool_size=int(pool)))\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(second_neuron, activation='relu'))\r\n",
    "model.add(Dropout(dropout/10))\r\n",
    "model.add(Dense(third_neuron, activation='softmax'))\r\n",
    "\r\n",
    "input1 = model(close_history)\r\n",
    "\r\n",
    "connect = Concatenate()([input1, input2])\r\n",
    "\r\n",
    "for _ in range(int(hidden_layers) - 1):\r\n",
    "  connect = Dense(100)(connect)\r\n",
    "  connect = BatchNormalization()(connect)\r\n",
    "  connect = LeakyReLU()(connect)\r\n",
    "\r\n",
    "predict = Dense(1, activation='relu')(connect)\r\n",
    "model=Model(inputs=[close_history, input2], outputs=predict)\r\n",
    "\r\n",
    "\r\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\r\n",
    "history = model.fit(call_X_train, call_y_train, \r\n",
    "                    batch_size=4900, epochs=290, \r\n",
    "                    validation_split = 0.01,\r\n",
    "                    callbacks=[tensorboard_callback],\r\n",
    "                    verbose=1)\r\n",
    "model.save('cnn.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from .utilties import utilties"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "line1 = utilties.error_metrics(call_y_test, model.predict(call_X_test, batch_size=4900).reshape(call_y_test.shape[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('MSE: {:.2f} & RMSE: {:.2f} & BIAS: {:.2f}% & AAPE: {:.2f}% & MAPE: {:.2f}% & PE5: {:.2f}\\% & PE10: {:.2f}% & PE20: {:.2f}% '.format(*line1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Returns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Create a dataframe with only the Close Stock Price Column\r\n",
    "data_target = History.filter(['Close'])\r\n",
    "\r\n",
    "# Convert the dataframe to a numpy array to train the CNN model\r\n",
    "target = data_target.values\r\n",
    "\r\n",
    "# Splitting the dataset into training and test\r\n",
    "# Target Variable: Close stock price value\r\n",
    "\r\n",
    "training_data_len = math.ceil(len(target)* 0.75) # training set has 75% of the data\r\n",
    "training_data_len\r\n",
    "\r\n",
    "# Normalizing data before model fitting using MinMaxScaler\r\n",
    "# Feature Scaling\r\n",
    "sc = MinMaxScaler(feature_range=(0,1))\r\n",
    "training_scaled_data = sc.fit_transform(target)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "jcEyg43v56BH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# Create a training dataset containing the last 30-day closing price values we want to use to estimate the 31st closing price value.\r\n",
    "train_data = training_scaled_data[0:training_data_len  , : ]\r\n",
    "\r\n",
    "X_train = []\r\n",
    "y_train = []\r\n",
    "for i in range(30, len(train_data)):\r\n",
    "    X_train.append(train_data[i-30:i, 0])\r\n",
    "    y_train.append(train_data[i, 0])\r\n",
    "\r\n",
    "X_train, y_train = np.array(X_train), np.array(y_train) # converting into numpy sequences to train the LSTM model\r\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\r\n",
    "print('Number of rows and columns: ', X_train.shape)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNxeWhbCUWse",
    "outputId": "c7438c11-1fd7-43d9-be75-3258e4f1b23f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "first_neuron, second_neuron, third_neuron, dropout, hidden_layers, pool= Params\r\n",
    "with tf.device('/Gpu:0'): \r\n",
    "  model = Sequential()\r\n",
    "  model.add(Conv1D(first_neuron, kernel_size=1, activation='relu', input_shape= (X_train.shape[1], 1)))\r\n",
    "  model.add(MaxPooling1D(pool_size=int(pool)))\r\n",
    "  model.add(Flatten())\r\n",
    "  model.add(Dense(second_neuron, activation='relu'))\r\n",
    "  model.add(Dropout(dropout/10))\r\n",
    "  model.add(Dense(third_neuron, activation='softmax'))\r\n",
    "  # Adding the output layer\r\n",
    "  model.add(Dense(units = 1))\r\n",
    "  # Compiling the RNN\r\n",
    "  model.compile(optimizer = 'adam', loss = 'mean_squared_error')\r\n",
    "  # Fitting the RNN to the Training set\r\n",
    "  model.fit(X_train, y_train, epochs = 90, batch_size = 1)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oyy_CCNWUbRu",
    "outputId": "29312a98-925f-44d2-c3f1-a87d6423bb03"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Getting the predicted stock price\r\n",
    "test_data = training_scaled_data[training_data_len - 30: , : ]\r\n",
    "\r\n",
    "#Create the x_test and y_test data sets\r\n",
    "X_test = []\r\n",
    "y_test =  target[training_data_len : , : ]\r\n",
    "for i in range(30,len(test_data)):\r\n",
    "    X_test.append(test_data[i-30:i,0])\r\n",
    "\r\n",
    "# Convert x_test to a numpy array\r\n",
    "X_test = np.array(X_test)\r\n",
    "\r\n",
    "#Reshape the data into the shape accepted by the CNN\r\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmtIqee1UhFc",
    "outputId": "b197009d-ad74-49d1-8947-1682349785de"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "predicted_stock_price = model.predict(X_test)\r\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\r\n",
    "predicted_stock_price_2 = model.predict(X_train)\r\n",
    "predicted_stock_price_2 = sc.inverse_transform(predicted_stock_price)\r\n",
    "valid = data_target[training_data_len:]"
   ],
   "outputs": [],
   "metadata": {
    "id": "s2IMSANaUmZa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# save returns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "valid.to_csv('CNN-STOCK.csv')"
   ],
   "outputs": [],
   "metadata": {
    "id": "CDNMONvNUwa7"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}