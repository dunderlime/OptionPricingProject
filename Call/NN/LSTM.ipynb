{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from keras.models import Sequential, Model, load_model\r\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, LSTM, Bidirectional, Input, Concatenate, Dropout\r\n",
    "from keras.callbacks import TensorBoard\r\n",
    "from keras.optimizers import Adam\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "import tensorflow as tf\r\n",
    "from geneticalgorithm import geneticalgorithm as ga\r\n",
    "import math\r\n",
    "import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "call_df = pd.read_csv('')\r\n",
    "History = pd.read_csv('')\r\n",
    "risk_free_asset = pd.read_csv('')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Format and split data before training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "# Add risk-free asset as feature to df on date\r\n",
    "n_timesteps = 1\r\n",
    "\r\n",
    "padded = np.insert(risk_free_asset.Rate.values, 0, np.array([np.nan] * n_timesteps))\r\n",
    "rolled = np.column_stack([np.roll(padded, i) for i in range(n_timesteps)])\r\n",
    "rolled = rolled[~np.isnan(rolled).any(axis=1)]\r\n",
    "rolled = np.column_stack((risk_free_asset.Date.values[n_timesteps - 1:], rolled))\r\n",
    "price_history = pd.DataFrame(data=rolled)\r\n",
    "joined = call_df.join(price_history.set_index(0), on='Date')\r\n",
    "\r\n",
    "joined['r'] = joined[1]\r\n",
    "call_df = joined.drop(columns=[1,'LTP', 'Risk_free_rate'],axis=1)\r\n",
    "\r\n",
    "\r\n",
    "#Creates the stock dynamics for the n_timesteps back.\r\n",
    "\r\n",
    "underlying=History\r\n",
    "n_timesteps = 30\r\n",
    "padded = np.insert(underlying.Close.values, 0, np.array([np.nan] * n_timesteps))\r\n",
    "rolled = np.column_stack([np.roll(padded, i) for i in range(n_timesteps)])\r\n",
    "rolled = rolled[~np.isnan(rolled).any(axis=1)]\r\n",
    "rolled = np.column_stack((underlying.Date.values[n_timesteps - 1:], rolled))\r\n",
    "price_history = pd.DataFrame(data=rolled)\r\n",
    "joined = call_df.join(price_history.set_index(0), on='Date')\r\n",
    "call_df=joined\r\n",
    "call_df = call_df.drop(columns=['Date','Expiry'])\r\n",
    "call_df = call_df.dropna()\r\n",
    "\r\n",
    "features = 4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "call_df=call_df[['Strike Price','Close','nDiff','r','Underlying Value']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "call_X_train, call_X_test, call_y_train, call_y_test = train_test_split(call_df.drop(columns=['Close'],axis=1).values,\r\n",
    "                                                                        (call_df['Close']).values,\r\n",
    "                                                                        #shuffle=False,\r\n",
    "                                                                         random_state=42,\r\n",
    "                                                                  test_size=0.01)\r\n",
    "call_X_test= np.array(call_X_test, dtype=np.float64)\r\n",
    "call_y_test= np.array(call_y_test, dtype=np.float64)\r\n",
    "call_X_train=np.asarray(call_X_train).astype(np.float64)\r\n",
    "\r\n",
    "\r\n",
    "call_X_train = [call_X_train[:, -n_timesteps:].reshape(call_X_train.shape[0], n_timesteps, 1), call_X_train[:, :4]]\r\n",
    "call_X_test = [call_X_test[:, -n_timesteps:].reshape(call_X_test.shape[0], n_timesteps, 1), call_X_test[:, :4]]\r\n",
    "\r\n",
    "\r\n",
    "call_y_train=np.asarray(call_y_train).astype(np.float64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calibration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "varbound=np.array([[1,200],[1,200],[1,200],[0,2],[1,15],[1,200],[10,4000]])\r\n",
    "algorithm_param = {'max_num_iteration': 100,\\\r\n",
    "            'population_size':15,\\\r\n",
    "            'mutation_probability':0.1,\\\r\n",
    "            'elit_ratio': 0.01,\\\r\n",
    "            'crossover_probability': 0.5,\\\r\n",
    "            'parents_portion': 0.3,\\\r\n",
    "            'crossover_type':'uniform',\\\r\n",
    "            'max_iteration_without_improv':5}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def LSTM_GA():\r\n",
    "    def f(x):\r\n",
    "        first_neuron, second_neuron, third_neuron, dropout, hidden_layers, fort_neuron, neurons = x\r\n",
    "        close_history = Input((n_timesteps, 1))\r\n",
    "        input2 = Input((features,))\r\n",
    "        with tf.device('/device:GPU:0'):\r\n",
    "            lstm = Sequential()\r\n",
    "            lstm.add(Bidirectional(LSTM(units=int(first_neuron), input_shape=(n_timesteps, 1), return_sequences=True)))\r\n",
    "            lstm.add(Bidirectional(LSTM(units=int(second_neuron), return_sequences=True)))\r\n",
    "            lstm.add(Bidirectional(LSTM(units=int(third_neuron), return_sequences=True)))\r\n",
    "            lstm.add(Bidirectional(LSTM(units=int(fort_neuron), return_sequences=False)))\r\n",
    "            input1 = lstm(close_history)\r\n",
    "            connect = Concatenate()([input1, input2])\r\n",
    "            \r\n",
    "            for _ in range(int(hidden_layers) - 1):\r\n",
    "                connect = Dense(int(neurons))(connect)\r\n",
    "                connect = BatchNormalization()(connect)\r\n",
    "                connect = Dropout(dropout/10)(connect)\r\n",
    "                connect = LeakyReLU()(connect)\r\n",
    "            predict = Dense(1, activation='relu')(connect)\r\n",
    "\r\n",
    "            model=Model(inputs=[close_history, input2], outputs=predict)\r\n",
    "\r\n",
    "            model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\r\n",
    "\r\n",
    "            out = model.fit(call_X_train, call_y_train, \r\n",
    "                        batch_size=250,\r\n",
    "                        epochs=200,\r\n",
    "                        validation_split = 0.01,\r\n",
    "                        validation_data=(call_X_test, call_y_test),\r\n",
    "                        callbacks=[TensorBoard()],\r\n",
    "                        verbose=1)\r\n",
    "            \r\n",
    "            return np.sqrt(np.mean(np.square(call_y_test-model.predict(call_X_test, batch_size=250).reshape(call_y_test.shape[0]))))\r\n",
    "        \r\n",
    "    model=ga(function = f,\\\r\n",
    "            dimension = 7,\\\r\n",
    "            variable_type = 'int',\\\r\n",
    "            variable_boundaries = varbound,\\\r\n",
    "            function_timeout = 4500,\r\n",
    "            algorithm_parameters = algorithm_param,\r\n",
    "         convergence_curve = True,\r\n",
    "         progress_bar = True)\r\n",
    "\r\n",
    "    model.run()\r\n",
    "    return model.best_variable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "LSTM_params = LSTM_GA()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Option traning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "first_neuron, second_neuron, third_neuron, dropout, hidden_layers, fort_neuron, neurons = LSTM_params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "source": [
    "close_history =Input((n_timesteps, 1))\r\n",
    "input2 = Input((features,))\r\n",
    "with tf.device('/device:GPU:0'):\r\n",
    "    lstm = Sequential()\r\n",
    "    lstm.add(Bidirectional(LSTM(units=int(first_neuron), input_shape=(n_timesteps, 1), return_sequences=True)))\r\n",
    "    lstm.add(Bidirectional(LSTM(units=int(second_neuron), return_sequences=True)))\r\n",
    "    lstm.add(Bidirectional(LSTM(units=int(third_neuron), return_sequences=True)))\r\n",
    "    lstm.add(Bidirectional(LSTM(units=int(fort_neuron), return_sequences=False)))\r\n",
    "    input1 = lstm(close_history)\r\n",
    "    connect = Concatenate()([input1, input2])\r\n",
    "    \r\n",
    "    for _ in range(int(hidden_layers) - 1):\r\n",
    "        connect = Dense(int(neurons))(connect)\r\n",
    "        connect = BatchNormalization()(connect)\r\n",
    "        connect = Dropout(dropout/10)(connect)\r\n",
    "        connect = LeakyReLU()(connect)\r\n",
    "    predict = Dense(1, activation='relu')(connect)\r\n",
    "\r\n",
    "    model = Model(inputs=[close_history, input2], outputs=predict)\r\n",
    "\r\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\r\n",
    "history = model.fit(call_X_train, call_y_train, \r\n",
    "                    batch_size = 4900, epochs = 290, \r\n",
    "                    validation_split = 0.01,\r\n",
    "                    callbacks = [tensorboard_callback],\r\n",
    "                    verbose = 1)\r\n",
    "model.save('lstm.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from .utilties import utilties"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "line1 = utilties.error_metrics(call_y_test, model.predict(call_X_test, batch_size=4900).reshape(call_y_test.shape[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print('MSE: {:.2f} & RMSE: {:.2f} & BIAS: {:.2f}% & AAPE: {:.2f}% & MAPE: {:.2f}% & PE5: {:.2f}\\% & PE10: {:.2f}% & PE20: {:.2f}% '.format(*line1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Returns\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "source": [
    "# Create a dataframe with only the Close Stock Price Column\r\n",
    "data_target = History.filter(['Close'])\r\n",
    "\r\n",
    "# Convert the dataframe to a numpy array to train the LSTM model\r\n",
    "target = data_target.values\r\n",
    "\r\n",
    "# Splitting the dataset into training and test\r\n",
    "# Target Variable: Close stock price value\r\n",
    "\r\n",
    "training_data_len = math.ceil(len(target)* 0.75) # training set has 75% of the data\r\n",
    "training_data_len\r\n",
    "\r\n",
    "# Normalizing data before model fitting using MinMaxScaler\r\n",
    "# Feature Scaling\r\n",
    "sc = MinMaxScaler(feature_range=(0,1))\r\n",
    "training_scaled_data = sc.fit_transform(target)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# Create a training dataset containing the last 30-day closing price values we want to use to estimate the 31st closing price value.\r\n",
    "train_data = training_scaled_data[0:training_data_len  , : ]\r\n",
    "\r\n",
    "X_train = []\r\n",
    "y_train = []\r\n",
    "for i in range(30, len(train_data)):\r\n",
    "    X_train.append(train_data[i-30:i, 0])\r\n",
    "    y_train.append(train_data[i, 0])\r\n",
    "\r\n",
    "X_train, y_train = np.array(X_train), np.array(y_train) # converting into numpy sequences to train the LSTM model\r\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\r\n",
    "print('Number of rows and columns: ', X_train.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Sequential()\r\n",
    "#Adding the first LSTM layer and some Dropout regularisation\r\n",
    "model.add(LSTM(units = 8, return_sequences = True, input_shape = (X_train.shape[1], 1)))\r\n",
    "model.add(Bidirectional(LSTM(units=8, return_sequences=True)))\r\n",
    "model.add(Bidirectional(LSTM(units=8, return_sequences=True)))\r\n",
    "model.add(Bidirectional(LSTM(units=8, return_sequences=False)))\r\n",
    "# Adding the output layer\r\n",
    "model.add(Dense(units = 1))\r\n",
    "# Compiling the RNN\r\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\r\n",
    "# Fitting the RNN to the Training set\r\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Getting the predicted stock price\r\n",
    "test_data = training_scaled_data[training_data_len - 30: , : ]\r\n",
    "\r\n",
    "#Create the x_test and y_test data sets\r\n",
    "X_test = []\r\n",
    "y_test =  target[training_data_len : , : ]\r\n",
    "for i in range(30,len(test_data)):\r\n",
    "    X_test.append(test_data[i-30:i,0])\r\n",
    "\r\n",
    "# Convert x_test to a numpy array\r\n",
    "X_test = np.array(X_test)\r\n",
    "\r\n",
    "#Reshape the data into the shape accepted by the LSTM\r\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\r\n",
    "print('Number of rows and columns: ', X_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "source": [
    "predicted_stock_price = model.predict(X_test)\r\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\r\n",
    "predicted_stock_price_2 = model.predict(X_train)\r\n",
    "predicted_stock_price_2 = sc.inverse_transform(predicted_stock_price)\r\n",
    "valid = data_target[training_data_len:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "source": [
    "valid.to_csv('LSTM-STOCK.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}